{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 中文情感分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: paddlenlp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (2.2.6)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.9.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.64.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.1.85)\n",
      "Requirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.4.4)\n",
      "Requirement already satisfied: paddlefsl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.1.0)\n",
      "Requirement already satisfied: seqeval in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (1.2.2)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.70.11.1)\n",
      "Requirement already satisfied: colorlog in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (4.1.0)\n",
      "Requirement already satisfied: jieba in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (0.42.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlenlp) (2.1.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets->paddlenlp) (2.22.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets->paddlenlp) (4.2.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets->paddlenlp) (0.18.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets->paddlenlp) (21.3)\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets->paddlenlp) (7.0.0)\n",
      "Requirement already satisfied: dill in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets->paddlenlp) (0.3.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets->paddlenlp) (1.1.5)\n",
      "Requirement already satisfied: xxhash in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets->paddlenlp) (3.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets->paddlenlp) (1.20.3)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets->paddlenlp) (3.8.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets->paddlenlp) (2022.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from datasets->paddlenlp) (0.5.1)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from h5py->paddlenlp) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from seqeval->paddlenlp) (0.24.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->paddlenlp) (5.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->paddlenlp) (4.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets->paddlenlp) (3.0.12)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from packaging->datasets->paddlenlp) (3.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets->paddlenlp) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets->paddlenlp) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets->paddlenlp) (1.25.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests>=2.19.0->datasets->paddlenlp) (3.0.4)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (1.6.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (0.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval->paddlenlp) (2.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets->paddlenlp) (6.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets->paddlenlp) (21.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets->paddlenlp) (1.2.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets->paddlenlp) (0.13.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets->paddlenlp) (4.0.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets->paddlenlp) (2.0.12)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets->paddlenlp) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from aiohttp->datasets->paddlenlp) (1.7.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from importlib-metadata->datasets->paddlenlp) (3.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->datasets->paddlenlp) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pandas->datasets->paddlenlp) (2.8.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade paddlenlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': '选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般', 'label': 1, 'qid': ''}\n",
      "{'text': '15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错', 'label': 1, 'qid': ''}\n",
      "{'text': '房间太小。其他的都一般。。。。。。。。。', 'label': 0, 'qid': ''}\n",
      "{'text': '1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.', 'label': 0, 'qid': ''}\n",
      "{'text': '今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量商量,单独出个第6卷,让我们的孩子不会有所遗憾。', 'label': 1, 'qid': ''}\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.datasets import load_dataset\r\n",
    "\r\n",
    "# 加载数据\r\n",
    "train_data, dev_data, test_data = load_dataset('chnsenticorp', splits=['train', 'dev', 'test'])\r\n",
    "\r\n",
    "# 查看数据\r\n",
    "for data in train_data[:5]:\r\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 2. 构建词表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PaddleNLP', '的', 'Taskflow', '是', '一个', '全能', '的', 'NLP', '工具']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\r\n",
    "import re\r\n",
    "\r\n",
    "from paddlenlp import Taskflow\r\n",
    "import numpy as np\r\n",
    "import paddle\r\n",
    "\r\n",
    "# 采用Taskflow作为切词工具\r\n",
    "word_segmenter = Taskflow('word_segmentation')\r\n",
    "word_segmenter('PaddleNLP的Taskflow是一个全能的NLP工具')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['选择珠江花园的原因就是方便，有电动扶梯直接到达海边，周围餐馆、食廊、商场、超市、摊位一应俱全。酒店装修一般，但还算整洁。 泳池在大堂的屋顶，因此很小，不过女儿倒是喜欢。 包的早餐是西式的，还算丰富。 服务吗，一般',\n",
       " '15.4寸笔记本的键盘确实爽，基本跟台式机差不多了，蛮喜欢数字小键盘，输数字特方便，样子也很美观，做工也相当不错',\n",
       " '房间太小。其他的都一般。。。。。。。。。',\n",
       " '1.接电源没有几分钟,电源适配器热的不行. 2.摄像头用不起来. 3.机盖的钢琴漆，手不能摸，一摸一个印. 4.硬盘分区不好办.',\n",
       " '今天才知道这书还有第6卷,真有点郁闷:为什么同一套书有两种版本呢?当当网是不是该跟出版社商量商量,单独出个第6卷,让我们的孩子不会有所遗憾。']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts = []\r\n",
    "for data in train_data:\r\n",
    "    texts.append(data['text'])\r\n",
    "for data in dev_data:\r\n",
    "    texts.append(data['text'])\r\n",
    "\r\n",
    "texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD] 0\n",
      "[UNK] 1\n",
      "了 2\n",
      "是 3\n",
      "我 4\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\r\n",
    "\r\n",
    "# 停用词\r\n",
    "stopwords = set(['的', '吗', '吧', '呀', '呜', '呢', '呗', ',', '，', '。', '？', '.', ';', ':', '!', ' '])\r\n",
    "\r\n",
    "def build_vocab(texts: List[str],\r\n",
    "                stopwords: List[str]=[],\r\n",
    "                num_words: int=None,\r\n",
    "                min_freq: int=10,\r\n",
    "                unk_token: str='[UNK]',\r\n",
    "                pad_token: str='[PAD]') -> Dict:\r\n",
    "    \"\"\"\r\n",
    "    Args:\r\n",
    "        texts: 原始语料库数据\r\n",
    "        stopwords: 停用词\r\n",
    "        num_words: 词典中最大的单词数\r\n",
    "        min_freq: 要保留词的最小词频\r\n",
    "    Returns:\r\n",
    "        word_index: 原始语料库的字典\r\n",
    "    \"\"\"\r\n",
    "    word_counts = defaultdict(int)\r\n",
    "    for text in texts:\r\n",
    "        if not text:\r\n",
    "            continue\r\n",
    "        for word in word_segmenter(text):\r\n",
    "            if word in stopwords:\r\n",
    "                continue\r\n",
    "            word_counts[word] += 1\r\n",
    "    \r\n",
    "    wcounts = []\r\n",
    "    for word, count in word_counts.items():\r\n",
    "        if count < min_freq:\r\n",
    "            continue\r\n",
    "        wcounts.append((word, count))\r\n",
    "    \r\n",
    "    wcounts.sort(key=lambda x: x[1], reverse=True)\r\n",
    "    # -2 是为了unk_token 和 pad_token\r\n",
    "    if num_words is not None and len(wcounts) > (num_words - 2):\r\n",
    "        wcounts = wcounts[:(num_words - 2)]\r\n",
    "    sorted_voc = [pad_token, unk_token]\r\n",
    "    sorted_voc.extend(wc[0] for wc in wcounts)\r\n",
    "    word_index = dict(zip(sorted_voc, list(range(len(sorted_voc)))))\r\n",
    "    return word_index\r\n",
    "\r\n",
    "word2idx = build_vocab(\r\n",
    "    texts=texts,\r\n",
    "    stopwords=stopwords,\r\n",
    "    min_freq=5\r\n",
    ")\r\n",
    "cnt = 0\r\n",
    "for word, idx in word2idx.items():\r\n",
    "    print(word, idx)\r\n",
    "    cnt += 1\r\n",
    "    if cnt == 5:\r\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from paddlenlp.data import Vocab\r\n",
    "\r\n",
    "vocab = Vocab.from_dict(\r\n",
    "    token_to_idx=word2idx,\r\n",
    "    unk_token='[UNK]',\r\n",
    "    pad_token='[PAD]'\r\n",
    ")\r\n",
    "\r\n",
    "vocab_json_str = vocab.to_json('./vocab.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. 数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked Result: \n",
      " [[1 2 3 4]\n",
      " [3 4 5 6]\n",
      " [5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.data import Stack, Pad, Tuple\r\n",
    "\r\n",
    "a = [1, 2, 3, 4]\r\n",
    "b = [3, 4, 5, 6]\r\n",
    "c = [5, 6, 7, 8]\r\n",
    "res = Stack()([a, b, c])\r\n",
    "print('Stacked Result: \\n', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded Result: \n",
      " [[1 2 3 4]\n",
      " [5 6 7 0]\n",
      " [8 9 0 0]]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4]\r\n",
    "b = [5, 6, 7]\r\n",
    "c = [8, 9]\r\n",
    "res = Pad(pad_val=0)([a, b, c])\r\n",
    "print('Padded Result: \\n', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: \n",
      " [[1 2 3 4]\n",
      " [5 6 7 0]\n",
      " [8 9 0 0]]\n",
      "labels: \n",
      " [[1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "data = [\r\n",
    "    [[1, 2, 3, 4], [1]],\r\n",
    "    [[5, 6, 7], [0]],\r\n",
    "    [[8, 9], [1]]\r\n",
    "]\r\n",
    "\r\n",
    "batchify_fn = Tuple(Pad(pad_val=0), Stack())\r\n",
    "ids, labels = batchify_fn(data)\r\n",
    "print('ids: \\n', ids)\r\n",
    "print('labels: \\n', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from functools import partial\r\n",
    "from paddlenlp.data import JiebaTokenizer\r\n",
    "\r\n",
    "def convert_example(example, tokenizer, is_test=False):\r\n",
    "    \"\"\"\r\n",
    "    Args:\r\n",
    "        example: 输入数据列表，包含文本和标签\r\n",
    "        tokenizer: 使用jieba来分割中文文本\r\n",
    "        is_test: 输入数据是否为测试数据\r\n",
    "    Returns:\r\n",
    "        input_ids: 词id列表\r\n",
    "        valid_length：输入文本有效长度\r\n",
    "        label: 输入标签\r\n",
    "    \"\"\"\r\n",
    "    input_ids = tokenizer.encode(example['text'])\r\n",
    "    valid_length = np.array(len(input_ids), dtype='int64')\r\n",
    "    input_ids = np.array(input_ids, dtype='int64')\r\n",
    "\r\n",
    "    if not is_test:\r\n",
    "        label = np.array(example['label'], dtype='int64')\r\n",
    "        return input_ids, valid_length, label\r\n",
    "    else:\r\n",
    "        return input_ids, valid_length\r\n",
    "\r\n",
    "tokenizer = JiebaTokenizer(vocab=vocab)\r\n",
    "trans_fn = partial(convert_example, tokenizer=tokenizer, is_test=False)\r\n",
    "\r\n",
    "batchify_fn = lambda samples, fn = Tuple(\r\n",
    "    # input_ids\r\n",
    "    Pad(pad_val=vocab.token_to_idx.get('[PAD]', 0)),\r\n",
    "    # valid_length (seq len)\r\n",
    "    Stack(dtype='int64'),\r\n",
    "    # label\r\n",
    "    Stack(dtype='int64')\r\n",
    "): [data for data in fn(samples)]\r\n",
    "\r\n",
    "def create_dataloader(dataset,\r\n",
    "                    trans_fn=None,\r\n",
    "                    mode='train',\r\n",
    "                    batch_size=1,\r\n",
    "                    batchify_fn=None) -> paddle.io.DataLoader:\r\n",
    "    \"\"\"\r\n",
    "    Args:\r\n",
    "        dataset: 数据集\r\n",
    "        trans_fn: 将数据样本转为input_ids, seq len, label\r\n",
    "        mode: 是否为训练模式\r\n",
    "        batch_size: mini-batch的大小\r\n",
    "        batchify_fn: 将mini-batch数据合并为一个列表\r\n",
    "    Returns:\r\n",
    "        dataloader: 用于生成batch的dataloader\r\n",
    "    \"\"\"\r\n",
    "    if trans_fn:\r\n",
    "        dataset = dataset.map(trans_fn)\r\n",
    "    \r\n",
    "    shuffle = True if mode=='train' else False\r\n",
    "    if mode == 'train':\r\n",
    "        sampler = paddle.io.DistributedBatchSampler(\r\n",
    "            dataset=dataset,\r\n",
    "            batch_size=batch_size,\r\n",
    "            shuffle=shuffle\r\n",
    "        )\r\n",
    "    else:\r\n",
    "        sampler = paddle.io.BatchSampler(\r\n",
    "            dataset=dataset,\r\n",
    "            batch_size=batch_size,\r\n",
    "            shuffle=shuffle\r\n",
    "        )\r\n",
    "    dataloader = paddle.io.DataLoader(\r\n",
    "        dataset=dataset,\r\n",
    "        batch_sampler=sampler,\r\n",
    "        collate_fn=batchify_fn\r\n",
    "    )\r\n",
    "    return dataloader\r\n",
    "\r\n",
    "batch_size = 64\r\n",
    "\r\n",
    "train_loader = create_dataloader(\r\n",
    "    dataset=train_data,\r\n",
    "    trans_fn=trans_fn,\r\n",
    "    mode='train',\r\n",
    "    batch_size=batch_size,\r\n",
    "    batchify_fn=batchify_fn\r\n",
    ")\r\n",
    "dev_loader = create_dataloader(\r\n",
    "    dataset=dev_data,\r\n",
    "    trans_fn=trans_fn,\r\n",
    "    mode='validation',\r\n",
    "    batch_size=batch_size,\r\n",
    "    batchify_fn=batchify_fn\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. 导入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from models.TextRNN import LSTMModel\r\n",
    "from models.TextCNN import TextCNNModel\r\n",
    "from models.TextBiLSTM_Att import BiLSTMAttentionModel, SelfAttention, SelfInteractiveAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LSTMModel(\r\n",
    "    vocab_size=len(vocab),\r\n",
    "    num_classes=len(train_data.label_list),\r\n",
    "    direction='bidirectional',\r\n",
    "    padding_idx=vocab.to_indices('[PAD]')\r\n",
    ")\r\n",
    "\r\n",
    "model = paddle.Model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 5. 构造优化器，损失函数和评价指标"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = paddle.optimizer.Adam(\r\n",
    "    parameters=model.parameters(),\r\n",
    "    learning_rate=5e-5\r\n",
    ")\r\n",
    "\r\n",
    "loss = paddle.nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "metric = paddle.metric.Accuracy()\r\n",
    "\r\n",
    "model.prepare(\r\n",
    "    optimizer=optimizer,\r\n",
    "    loss=loss,\r\n",
    "    metrics=metric\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 6. 模型训练与评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/10\n",
      "step  10/150 - loss: 0.7011 - acc: 0.5344 - 89ms/step\n",
      "step  20/150 - loss: 0.6996 - acc: 0.5328 - 84ms/step\n",
      "step  30/150 - loss: 0.6945 - acc: 0.5193 - 80ms/step\n",
      "step  40/150 - loss: 0.6898 - acc: 0.5160 - 77ms/step\n",
      "step  50/150 - loss: 0.6939 - acc: 0.5112 - 75ms/step\n",
      "step  60/150 - loss: 0.6921 - acc: 0.5112 - 75ms/step\n",
      "step  70/150 - loss: 0.6946 - acc: 0.5038 - 75ms/step\n",
      "step  80/150 - loss: 0.6931 - acc: 0.4992 - 74ms/step\n",
      "step  90/150 - loss: 0.6940 - acc: 0.5016 - 73ms/step\n",
      "step 100/150 - loss: 0.6939 - acc: 0.4995 - 72ms/step\n",
      "step 110/150 - loss: 0.6924 - acc: 0.5109 - 72ms/step\n",
      "step 120/150 - loss: 0.6922 - acc: 0.5207 - 72ms/step\n",
      "step 130/150 - loss: 0.6920 - acc: 0.5236 - 71ms/step\n",
      "step 140/150 - loss: 0.6923 - acc: 0.5320 - 72ms/step\n",
      "step 150/150 - loss: 0.6917 - acc: 0.5375 - 70ms/step\n",
      "save checkpoint at /home/aistudio/checkpoints/0\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.6918 - acc: 0.6281 - 70ms/step\n",
      "step 19/19 - loss: 0.6925 - acc: 0.6308 - 53ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 2/10\n",
      "step  10/150 - loss: 0.6915 - acc: 0.6625 - 81ms/step\n",
      "step  20/150 - loss: 0.6900 - acc: 0.6211 - 76ms/step\n",
      "step  30/150 - loss: 0.6911 - acc: 0.5839 - 78ms/step\n",
      "step  40/150 - loss: 0.6915 - acc: 0.5656 - 77ms/step\n",
      "step  50/150 - loss: 0.6917 - acc: 0.5575 - 78ms/step\n",
      "step  60/150 - loss: 0.6916 - acc: 0.5542 - 76ms/step\n",
      "step  70/150 - loss: 0.6902 - acc: 0.5475 - 77ms/step\n",
      "step  80/150 - loss: 0.6915 - acc: 0.5467 - 79ms/step\n",
      "step  90/150 - loss: 0.6867 - acc: 0.5542 - 78ms/step\n",
      "step 100/150 - loss: 0.6883 - acc: 0.5567 - 78ms/step\n",
      "step 110/150 - loss: 0.6871 - acc: 0.5632 - 78ms/step\n",
      "step 120/150 - loss: 0.6855 - acc: 0.5701 - 77ms/step\n",
      "step 130/150 - loss: 0.6875 - acc: 0.5782 - 76ms/step\n",
      "step 140/150 - loss: 0.6770 - acc: 0.5838 - 76ms/step\n",
      "step 150/150 - loss: 0.6823 - acc: 0.5873 - 75ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.6818 - acc: 0.6203 - 67ms/step\n",
      "step 19/19 - loss: 0.6857 - acc: 0.6358 - 50ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 3/10\n",
      "step  10/150 - loss: 0.6829 - acc: 0.6359 - 85ms/step\n",
      "step  20/150 - loss: 0.6859 - acc: 0.6352 - 78ms/step\n",
      "step  30/150 - loss: 0.6698 - acc: 0.6604 - 75ms/step\n",
      "step  40/150 - loss: 0.6660 - acc: 0.6750 - 75ms/step\n",
      "step  50/150 - loss: 0.6563 - acc: 0.6759 - 75ms/step\n",
      "step  60/150 - loss: 0.6459 - acc: 0.6927 - 74ms/step\n",
      "step  70/150 - loss: 0.6330 - acc: 0.6964 - 74ms/step\n",
      "step  80/150 - loss: 0.5656 - acc: 0.7064 - 74ms/step\n",
      "step  90/150 - loss: 0.5247 - acc: 0.7087 - 79ms/step\n",
      "step 100/150 - loss: 0.5504 - acc: 0.7155 - 78ms/step\n",
      "step 110/150 - loss: 0.5009 - acc: 0.7243 - 78ms/step\n",
      "step 120/150 - loss: 0.4447 - acc: 0.7311 - 77ms/step\n",
      "step 130/150 - loss: 0.4781 - acc: 0.7328 - 77ms/step\n",
      "step 140/150 - loss: 0.5013 - acc: 0.7403 - 77ms/step\n",
      "step 150/150 - loss: 0.4643 - acc: 0.7469 - 75ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.5514 - acc: 0.8234 - 68ms/step\n",
      "step 19/19 - loss: 0.4676 - acc: 0.8108 - 52ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 4/10\n",
      "step  10/150 - loss: 0.5162 - acc: 0.8406 - 95ms/step\n",
      "step  20/150 - loss: 0.4810 - acc: 0.8531 - 82ms/step\n",
      "step  30/150 - loss: 0.4518 - acc: 0.8542 - 79ms/step\n",
      "step  40/150 - loss: 0.4701 - acc: 0.8570 - 75ms/step\n",
      "step  50/150 - loss: 0.5731 - acc: 0.8578 - 75ms/step\n",
      "step  60/150 - loss: 0.5078 - acc: 0.8602 - 77ms/step\n",
      "step  70/150 - loss: 0.4276 - acc: 0.8596 - 76ms/step\n",
      "step  80/150 - loss: 0.4320 - acc: 0.8596 - 76ms/step\n",
      "step  90/150 - loss: 0.4230 - acc: 0.8635 - 75ms/step\n",
      "step 100/150 - loss: 0.4305 - acc: 0.8647 - 75ms/step\n",
      "step 110/150 - loss: 0.4378 - acc: 0.8663 - 74ms/step\n",
      "step 120/150 - loss: 0.4992 - acc: 0.8664 - 74ms/step\n",
      "step 130/150 - loss: 0.4738 - acc: 0.8667 - 74ms/step\n",
      "step 140/150 - loss: 0.4265 - acc: 0.8680 - 74ms/step\n",
      "step 150/150 - loss: 0.4264 - acc: 0.8693 - 72ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4809 - acc: 0.8625 - 70ms/step\n",
      "step 19/19 - loss: 0.4243 - acc: 0.8567 - 56ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 5/10\n",
      "step  10/150 - loss: 0.4345 - acc: 0.9031 - 104ms/step\n",
      "step  20/150 - loss: 0.4685 - acc: 0.8961 - 89ms/step\n",
      "step  30/150 - loss: 0.4340 - acc: 0.8953 - 83ms/step\n",
      "step  40/150 - loss: 0.4178 - acc: 0.8883 - 81ms/step\n",
      "step  50/150 - loss: 0.3966 - acc: 0.8897 - 78ms/step\n",
      "step  60/150 - loss: 0.3793 - acc: 0.8948 - 76ms/step\n",
      "step  70/150 - loss: 0.3670 - acc: 0.8962 - 76ms/step\n",
      "step  80/150 - loss: 0.3890 - acc: 0.8977 - 76ms/step\n",
      "step  90/150 - loss: 0.3916 - acc: 0.8998 - 75ms/step\n",
      "step 100/150 - loss: 0.4547 - acc: 0.9011 - 75ms/step\n",
      "step 110/150 - loss: 0.3881 - acc: 0.9020 - 74ms/step\n",
      "step 120/150 - loss: 0.4480 - acc: 0.9035 - 74ms/step\n",
      "step 130/150 - loss: 0.4045 - acc: 0.9038 - 75ms/step\n",
      "step 140/150 - loss: 0.4343 - acc: 0.9047 - 74ms/step\n",
      "step 150/150 - loss: 0.3646 - acc: 0.9054 - 73ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4953 - acc: 0.8719 - 87ms/step\n",
      "step 19/19 - loss: 0.4190 - acc: 0.8675 - 63ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 6/10\n",
      "step  10/150 - loss: 0.4032 - acc: 0.9391 - 86ms/step\n",
      "step  20/150 - loss: 0.4551 - acc: 0.9187 - 85ms/step\n",
      "step  30/150 - loss: 0.3990 - acc: 0.9182 - 81ms/step\n",
      "step  40/150 - loss: 0.3830 - acc: 0.9195 - 78ms/step\n",
      "step  50/150 - loss: 0.3572 - acc: 0.9169 - 77ms/step\n",
      "step  60/150 - loss: 0.4494 - acc: 0.9182 - 75ms/step\n",
      "step  70/150 - loss: 0.3756 - acc: 0.9194 - 74ms/step\n",
      "step  80/150 - loss: 0.3850 - acc: 0.9219 - 75ms/step\n",
      "step  90/150 - loss: 0.3988 - acc: 0.9193 - 75ms/step\n",
      "step 100/150 - loss: 0.4171 - acc: 0.9186 - 74ms/step\n",
      "step 110/150 - loss: 0.4146 - acc: 0.9192 - 73ms/step\n",
      "step 120/150 - loss: 0.4361 - acc: 0.9198 - 73ms/step\n",
      "step 130/150 - loss: 0.4241 - acc: 0.9207 - 74ms/step\n",
      "step 140/150 - loss: 0.4113 - acc: 0.9212 - 74ms/step\n",
      "step 150/150 - loss: 0.3645 - acc: 0.9227 - 72ms/step\n",
      "save checkpoint at /home/aistudio/checkpoints/5\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4758 - acc: 0.8922 - 76ms/step\n",
      "step 19/19 - loss: 0.4124 - acc: 0.8833 - 57ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 7/10\n",
      "step  10/150 - loss: 0.4208 - acc: 0.9266 - 83ms/step\n",
      "step  20/150 - loss: 0.3687 - acc: 0.9313 - 82ms/step\n",
      "step  30/150 - loss: 0.3478 - acc: 0.9349 - 78ms/step\n",
      "step  40/150 - loss: 0.3734 - acc: 0.9324 - 75ms/step\n",
      "step  50/150 - loss: 0.3728 - acc: 0.9322 - 75ms/step\n",
      "step  60/150 - loss: 0.3715 - acc: 0.9323 - 75ms/step\n",
      "step  70/150 - loss: 0.3659 - acc: 0.9350 - 74ms/step\n",
      "step  80/150 - loss: 0.4231 - acc: 0.9350 - 75ms/step\n",
      "step  90/150 - loss: 0.4033 - acc: 0.9358 - 75ms/step\n",
      "step 100/150 - loss: 0.3482 - acc: 0.9378 - 75ms/step\n",
      "step 110/150 - loss: 0.3950 - acc: 0.9376 - 76ms/step\n",
      "step 120/150 - loss: 0.3622 - acc: 0.9384 - 76ms/step\n",
      "step 130/150 - loss: 0.3727 - acc: 0.9368 - 76ms/step\n",
      "step 140/150 - loss: 0.3856 - acc: 0.9374 - 77ms/step\n",
      "step 150/150 - loss: 0.3703 - acc: 0.9377 - 75ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4533 - acc: 0.8984 - 112ms/step\n",
      "step 19/19 - loss: 0.4101 - acc: 0.8908 - 77ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 8/10\n",
      "step  10/150 - loss: 0.3895 - acc: 0.9437 - 93ms/step\n",
      "step  20/150 - loss: 0.4404 - acc: 0.9508 - 82ms/step\n",
      "step  30/150 - loss: 0.3673 - acc: 0.9526 - 79ms/step\n",
      "step  40/150 - loss: 0.4187 - acc: 0.9516 - 79ms/step\n",
      "step  50/150 - loss: 0.4054 - acc: 0.9506 - 76ms/step\n",
      "step  60/150 - loss: 0.3665 - acc: 0.9503 - 75ms/step\n",
      "step  70/150 - loss: 0.3773 - acc: 0.9493 - 74ms/step\n",
      "step  80/150 - loss: 0.4166 - acc: 0.9490 - 76ms/step\n",
      "step  90/150 - loss: 0.3737 - acc: 0.9479 - 77ms/step\n",
      "step 100/150 - loss: 0.3733 - acc: 0.9480 - 76ms/step\n",
      "step 110/150 - loss: 0.3338 - acc: 0.9477 - 75ms/step\n",
      "step 120/150 - loss: 0.3600 - acc: 0.9465 - 74ms/step\n",
      "step 130/150 - loss: 0.3766 - acc: 0.9470 - 74ms/step\n",
      "step 140/150 - loss: 0.3615 - acc: 0.9462 - 74ms/step\n",
      "step 150/150 - loss: 0.3632 - acc: 0.9473 - 73ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4729 - acc: 0.9000 - 70ms/step\n",
      "step 19/19 - loss: 0.4085 - acc: 0.8908 - 52ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 9/10\n",
      "step  10/150 - loss: 0.3670 - acc: 0.9391 - 98ms/step\n",
      "step  20/150 - loss: 0.3608 - acc: 0.9461 - 84ms/step\n",
      "step  30/150 - loss: 0.3675 - acc: 0.9495 - 83ms/step\n",
      "step  40/150 - loss: 0.3875 - acc: 0.9512 - 82ms/step\n",
      "step  50/150 - loss: 0.3812 - acc: 0.9497 - 80ms/step\n",
      "step  60/150 - loss: 0.3539 - acc: 0.9523 - 78ms/step\n",
      "step  70/150 - loss: 0.3549 - acc: 0.9525 - 77ms/step\n",
      "step  80/150 - loss: 0.3509 - acc: 0.9531 - 76ms/step\n",
      "step  90/150 - loss: 0.3861 - acc: 0.9533 - 75ms/step\n",
      "step 100/150 - loss: 0.3723 - acc: 0.9531 - 75ms/step\n",
      "step 110/150 - loss: 0.3641 - acc: 0.9530 - 75ms/step\n",
      "step 120/150 - loss: 0.3512 - acc: 0.9535 - 74ms/step\n",
      "step 130/150 - loss: 0.3369 - acc: 0.9528 - 73ms/step\n",
      "step 140/150 - loss: 0.3840 - acc: 0.9538 - 73ms/step\n",
      "step 150/150 - loss: 0.3940 - acc: 0.9527 - 72ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4327 - acc: 0.9094 - 77ms/step\n",
      "step 19/19 - loss: 0.4061 - acc: 0.8992 - 56ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 10/10\n",
      "step  10/150 - loss: 0.3891 - acc: 0.9672 - 84ms/step\n",
      "step  20/150 - loss: 0.3222 - acc: 0.9680 - 78ms/step\n",
      "step  30/150 - loss: 0.3477 - acc: 0.9667 - 74ms/step\n",
      "step  40/150 - loss: 0.3787 - acc: 0.9645 - 72ms/step\n",
      "step  50/150 - loss: 0.3645 - acc: 0.9616 - 73ms/step\n",
      "step  60/150 - loss: 0.3374 - acc: 0.9612 - 72ms/step\n",
      "step  70/150 - loss: 0.3692 - acc: 0.9594 - 71ms/step\n",
      "step  80/150 - loss: 0.3658 - acc: 0.9590 - 72ms/step\n",
      "step  90/150 - loss: 0.3704 - acc: 0.9589 - 72ms/step\n",
      "step 100/150 - loss: 0.3563 - acc: 0.9586 - 72ms/step\n",
      "step 110/150 - loss: 0.3329 - acc: 0.9592 - 72ms/step\n",
      "step 120/150 - loss: 0.3396 - acc: 0.9595 - 72ms/step\n",
      "step 130/150 - loss: 0.3323 - acc: 0.9593 - 73ms/step\n",
      "step 140/150 - loss: 0.3265 - acc: 0.9596 - 73ms/step\n",
      "step 150/150 - loss: 0.3486 - acc: 0.9592 - 72ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4538 - acc: 0.9031 - 69ms/step\n",
      "step 19/19 - loss: 0.4088 - acc: 0.8942 - 52ms/step\n",
      "Eval samples: 1200\n",
      "save checkpoint at /home/aistudio/checkpoints/final\n"
     ]
    }
   ],
   "source": [
    "model.fit(\r\n",
    "    train_data=train_loader,\r\n",
    "    eval_data=dev_loader,\r\n",
    "    epochs=10,\r\n",
    "    save_dir='./checkpoints',\r\n",
    "    save_freq=5\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/10\n",
      "step  10/150 - loss: 0.6928 - acc: 0.4766 - 76ms/step\n",
      "step  20/150 - loss: 0.6929 - acc: 0.4961 - 64ms/step\n",
      "step  30/150 - loss: 0.6925 - acc: 0.4995 - 61ms/step\n",
      "step  40/150 - loss: 0.6925 - acc: 0.5023 - 59ms/step\n",
      "step  50/150 - loss: 0.6932 - acc: 0.5006 - 60ms/step\n",
      "step  60/150 - loss: 0.6933 - acc: 0.4924 - 60ms/step\n",
      "step  70/150 - loss: 0.6922 - acc: 0.5018 - 60ms/step\n",
      "step  80/150 - loss: 0.6926 - acc: 0.5107 - 59ms/step\n",
      "step  90/150 - loss: 0.6912 - acc: 0.5149 - 60ms/step\n",
      "step 100/150 - loss: 0.6880 - acc: 0.5212 - 60ms/step\n",
      "step 110/150 - loss: 0.6926 - acc: 0.5209 - 60ms/step\n",
      "step 120/150 - loss: 0.6907 - acc: 0.5186 - 59ms/step\n",
      "step 130/150 - loss: 0.6913 - acc: 0.5169 - 59ms/step\n",
      "step 140/150 - loss: 0.6926 - acc: 0.5228 - 58ms/step\n",
      "step 150/150 - loss: 0.6886 - acc: 0.5288 - 57ms/step\n",
      "save checkpoint at /home/aistudio/checkpoints1/0\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.6901 - acc: 0.6391 - 69ms/step\n",
      "step 19/19 - loss: 0.6859 - acc: 0.6308 - 49ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 2/10\n",
      "step  10/150 - loss: 0.6796 - acc: 0.6312 - 71ms/step\n",
      "step  20/150 - loss: 0.6882 - acc: 0.6188 - 65ms/step\n",
      "step  30/150 - loss: 0.6773 - acc: 0.6224 - 62ms/step\n",
      "step  40/150 - loss: 0.6833 - acc: 0.6219 - 62ms/step\n",
      "step  50/150 - loss: 0.6636 - acc: 0.6291 - 60ms/step\n",
      "step  60/150 - loss: 0.6806 - acc: 0.6357 - 59ms/step\n",
      "step  70/150 - loss: 0.6915 - acc: 0.6431 - 59ms/step\n",
      "step  80/150 - loss: 0.6880 - acc: 0.6449 - 59ms/step\n",
      "step  90/150 - loss: 0.6654 - acc: 0.6465 - 59ms/step\n",
      "step 100/150 - loss: 0.6635 - acc: 0.6481 - 58ms/step\n",
      "step 110/150 - loss: 0.6595 - acc: 0.6499 - 58ms/step\n",
      "step 120/150 - loss: 0.6699 - acc: 0.6533 - 58ms/step\n",
      "step 130/150 - loss: 0.6590 - acc: 0.6573 - 61ms/step\n",
      "step 140/150 - loss: 0.6800 - acc: 0.6613 - 61ms/step\n",
      "step 150/150 - loss: 0.6024 - acc: 0.6664 - 60ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.6734 - acc: 0.7328 - 67ms/step\n",
      "step 19/19 - loss: 0.6464 - acc: 0.7350 - 48ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 3/10\n",
      "step  10/150 - loss: 0.6425 - acc: 0.7141 - 78ms/step\n",
      "step  20/150 - loss: 0.6536 - acc: 0.7164 - 67ms/step\n",
      "step  30/150 - loss: 0.6552 - acc: 0.7120 - 65ms/step\n",
      "step  40/150 - loss: 0.6618 - acc: 0.7125 - 63ms/step\n",
      "step  50/150 - loss: 0.6442 - acc: 0.7225 - 62ms/step\n",
      "step  60/150 - loss: 0.6385 - acc: 0.7245 - 62ms/step\n",
      "step  70/150 - loss: 0.6495 - acc: 0.7257 - 60ms/step\n",
      "step  80/150 - loss: 0.6578 - acc: 0.7289 - 62ms/step\n",
      "step  90/150 - loss: 0.6347 - acc: 0.7347 - 62ms/step\n",
      "step 100/150 - loss: 0.5882 - acc: 0.7392 - 62ms/step\n",
      "step 110/150 - loss: 0.5730 - acc: 0.7460 - 61ms/step\n",
      "step 120/150 - loss: 0.6199 - acc: 0.7474 - 61ms/step\n",
      "step 130/150 - loss: 0.5829 - acc: 0.7517 - 61ms/step\n",
      "step 140/150 - loss: 0.6267 - acc: 0.7550 - 61ms/step\n",
      "step 150/150 - loss: 0.6353 - acc: 0.7579 - 60ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.6182 - acc: 0.8250 - 70ms/step\n",
      "step 19/19 - loss: 0.5522 - acc: 0.8133 - 50ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 4/10\n",
      "step  10/150 - loss: 0.5868 - acc: 0.8125 - 74ms/step\n",
      "step  20/150 - loss: 0.5458 - acc: 0.8234 - 66ms/step\n",
      "step  30/150 - loss: 0.5765 - acc: 0.8276 - 64ms/step\n",
      "step  40/150 - loss: 0.5262 - acc: 0.8297 - 62ms/step\n",
      "step  50/150 - loss: 0.5181 - acc: 0.8266 - 61ms/step\n",
      "step  60/150 - loss: 0.5418 - acc: 0.8281 - 61ms/step\n",
      "step  70/150 - loss: 0.5735 - acc: 0.8286 - 60ms/step\n",
      "step  80/150 - loss: 0.5045 - acc: 0.8305 - 59ms/step\n",
      "step  90/150 - loss: 0.4850 - acc: 0.8321 - 58ms/step\n",
      "step 100/150 - loss: 0.5005 - acc: 0.8325 - 58ms/step\n",
      "step 110/150 - loss: 0.5442 - acc: 0.8344 - 58ms/step\n",
      "step 120/150 - loss: 0.5022 - acc: 0.8357 - 58ms/step\n",
      "step 130/150 - loss: 0.4990 - acc: 0.8365 - 58ms/step\n",
      "step 140/150 - loss: 0.4918 - acc: 0.8360 - 58ms/step\n",
      "step 150/150 - loss: 0.5164 - acc: 0.8361 - 57ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.5683 - acc: 0.8406 - 70ms/step\n",
      "step 19/19 - loss: 0.4955 - acc: 0.8425 - 51ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 5/10\n",
      "step  10/150 - loss: 0.5160 - acc: 0.8453 - 73ms/step\n",
      "step  20/150 - loss: 0.4244 - acc: 0.8602 - 65ms/step\n",
      "step  30/150 - loss: 0.4849 - acc: 0.8656 - 63ms/step\n",
      "step  40/150 - loss: 0.5634 - acc: 0.8645 - 61ms/step\n",
      "step  50/150 - loss: 0.4479 - acc: 0.8678 - 60ms/step\n",
      "step  60/150 - loss: 0.4524 - acc: 0.8685 - 59ms/step\n",
      "step  70/150 - loss: 0.5007 - acc: 0.8694 - 60ms/step\n",
      "step  80/150 - loss: 0.5119 - acc: 0.8697 - 60ms/step\n",
      "step  90/150 - loss: 0.5551 - acc: 0.8691 - 60ms/step\n",
      "step 100/150 - loss: 0.4987 - acc: 0.8702 - 60ms/step\n",
      "step 110/150 - loss: 0.4650 - acc: 0.8720 - 60ms/step\n",
      "step 120/150 - loss: 0.4687 - acc: 0.8723 - 59ms/step\n",
      "step 130/150 - loss: 0.5126 - acc: 0.8728 - 59ms/step\n",
      "step 140/150 - loss: 0.5288 - acc: 0.8740 - 59ms/step\n",
      "step 150/150 - loss: 0.4631 - acc: 0.8730 - 58ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.5323 - acc: 0.8594 - 70ms/step\n",
      "step 19/19 - loss: 0.4666 - acc: 0.8583 - 50ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 6/10\n",
      "step  10/150 - loss: 0.5032 - acc: 0.9141 - 68ms/step\n",
      "step  20/150 - loss: 0.4818 - acc: 0.9047 - 69ms/step\n",
      "step  30/150 - loss: 0.4696 - acc: 0.8964 - 66ms/step\n",
      "step  40/150 - loss: 0.4206 - acc: 0.8953 - 64ms/step\n",
      "step  50/150 - loss: 0.4174 - acc: 0.8931 - 63ms/step\n",
      "step  60/150 - loss: 0.4512 - acc: 0.8914 - 62ms/step\n",
      "step  70/150 - loss: 0.5249 - acc: 0.8884 - 61ms/step\n",
      "step  80/150 - loss: 0.4399 - acc: 0.8883 - 60ms/step\n",
      "step  90/150 - loss: 0.3901 - acc: 0.8918 - 60ms/step\n",
      "step 100/150 - loss: 0.4787 - acc: 0.8922 - 59ms/step\n",
      "step 110/150 - loss: 0.4449 - acc: 0.8925 - 59ms/step\n",
      "step 120/150 - loss: 0.4784 - acc: 0.8922 - 59ms/step\n",
      "step 130/150 - loss: 0.4827 - acc: 0.8915 - 59ms/step\n",
      "step 140/150 - loss: 0.4949 - acc: 0.8926 - 59ms/step\n",
      "step 150/150 - loss: 0.4297 - acc: 0.8928 - 57ms/step\n",
      "save checkpoint at /home/aistudio/checkpoints1/5\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.5091 - acc: 0.8734 - 71ms/step\n",
      "step 19/19 - loss: 0.4446 - acc: 0.8683 - 51ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 7/10\n",
      "step  10/150 - loss: 0.3973 - acc: 0.9031 - 78ms/step\n",
      "step  20/150 - loss: 0.3889 - acc: 0.9023 - 68ms/step\n",
      "step  30/150 - loss: 0.3668 - acc: 0.9047 - 65ms/step\n",
      "step  40/150 - loss: 0.4246 - acc: 0.9047 - 62ms/step\n",
      "step  50/150 - loss: 0.5038 - acc: 0.9025 - 61ms/step\n",
      "step  60/150 - loss: 0.3851 - acc: 0.9068 - 62ms/step\n",
      "step  70/150 - loss: 0.4029 - acc: 0.9058 - 61ms/step\n",
      "step  80/150 - loss: 0.4236 - acc: 0.9059 - 62ms/step\n",
      "step  90/150 - loss: 0.3848 - acc: 0.9078 - 61ms/step\n",
      "step 100/150 - loss: 0.4548 - acc: 0.9062 - 60ms/step\n",
      "step 110/150 - loss: 0.4230 - acc: 0.9055 - 60ms/step\n",
      "step 120/150 - loss: 0.4065 - acc: 0.9073 - 60ms/step\n",
      "step 130/150 - loss: 0.4590 - acc: 0.9067 - 60ms/step\n",
      "step 140/150 - loss: 0.3959 - acc: 0.9068 - 60ms/step\n",
      "step 150/150 - loss: 0.3913 - acc: 0.9056 - 59ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4988 - acc: 0.8766 - 71ms/step\n",
      "step 19/19 - loss: 0.4405 - acc: 0.8800 - 50ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 8/10\n",
      "step  10/150 - loss: 0.4093 - acc: 0.9078 - 85ms/step\n",
      "step  20/150 - loss: 0.4049 - acc: 0.9141 - 74ms/step\n",
      "step  30/150 - loss: 0.3888 - acc: 0.9198 - 68ms/step\n",
      "step  40/150 - loss: 0.4687 - acc: 0.9234 - 75ms/step\n",
      "step  50/150 - loss: 0.3915 - acc: 0.9228 - 72ms/step\n",
      "step  60/150 - loss: 0.4116 - acc: 0.9250 - 69ms/step\n",
      "step  70/150 - loss: 0.4063 - acc: 0.9239 - 67ms/step\n",
      "step  80/150 - loss: 0.4008 - acc: 0.9197 - 64ms/step\n",
      "step  90/150 - loss: 0.4171 - acc: 0.9175 - 67ms/step\n",
      "step 100/150 - loss: 0.4149 - acc: 0.9153 - 65ms/step\n",
      "step 110/150 - loss: 0.4255 - acc: 0.9156 - 64ms/step\n",
      "step 120/150 - loss: 0.4225 - acc: 0.9158 - 64ms/step\n",
      "step 130/150 - loss: 0.4208 - acc: 0.9165 - 63ms/step\n",
      "step 140/150 - loss: 0.3839 - acc: 0.9169 - 63ms/step\n",
      "step 150/150 - loss: 0.4042 - acc: 0.9175 - 61ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4832 - acc: 0.8844 - 79ms/step\n",
      "step 19/19 - loss: 0.4316 - acc: 0.8867 - 54ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 9/10\n",
      "step  10/150 - loss: 0.4460 - acc: 0.9219 - 72ms/step\n",
      "step  20/150 - loss: 0.3561 - acc: 0.9273 - 62ms/step\n",
      "step  30/150 - loss: 0.3912 - acc: 0.9214 - 60ms/step\n",
      "step  40/150 - loss: 0.3962 - acc: 0.9246 - 59ms/step\n",
      "step  50/150 - loss: 0.4014 - acc: 0.9256 - 58ms/step\n",
      "step  60/150 - loss: 0.3891 - acc: 0.9250 - 57ms/step\n",
      "step  70/150 - loss: 0.3570 - acc: 0.9277 - 57ms/step\n",
      "step  80/150 - loss: 0.3824 - acc: 0.9260 - 58ms/step\n",
      "step  90/150 - loss: 0.3761 - acc: 0.9252 - 58ms/step\n",
      "step 100/150 - loss: 0.3749 - acc: 0.9263 - 57ms/step\n",
      "step 110/150 - loss: 0.3888 - acc: 0.9256 - 57ms/step\n",
      "step 120/150 - loss: 0.4096 - acc: 0.9266 - 57ms/step\n",
      "step 130/150 - loss: 0.3747 - acc: 0.9257 - 57ms/step\n",
      "step 140/150 - loss: 0.3561 - acc: 0.9267 - 58ms/step\n",
      "step 150/150 - loss: 0.3792 - acc: 0.9260 - 57ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4716 - acc: 0.8984 - 75ms/step\n",
      "step 19/19 - loss: 0.4287 - acc: 0.8950 - 54ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 10/10\n",
      "step  10/150 - loss: 0.4165 - acc: 0.9281 - 81ms/step\n",
      "step  20/150 - loss: 0.3994 - acc: 0.9352 - 70ms/step\n",
      "step  30/150 - loss: 0.3822 - acc: 0.9318 - 64ms/step\n",
      "step  40/150 - loss: 0.3948 - acc: 0.9352 - 62ms/step\n",
      "step  50/150 - loss: 0.4199 - acc: 0.9366 - 61ms/step\n",
      "step  60/150 - loss: 0.4237 - acc: 0.9346 - 59ms/step\n",
      "step  70/150 - loss: 0.3861 - acc: 0.9350 - 58ms/step\n",
      "step  80/150 - loss: 0.3936 - acc: 0.9334 - 58ms/step\n",
      "step  90/150 - loss: 0.3735 - acc: 0.9330 - 58ms/step\n",
      "step 100/150 - loss: 0.4147 - acc: 0.9330 - 57ms/step\n",
      "step 110/150 - loss: 0.4135 - acc: 0.9338 - 57ms/step\n",
      "step 120/150 - loss: 0.4408 - acc: 0.9335 - 57ms/step\n",
      "step 130/150 - loss: 0.3998 - acc: 0.9337 - 57ms/step\n",
      "step 140/150 - loss: 0.4542 - acc: 0.9331 - 57ms/step\n",
      "step 150/150 - loss: 0.3499 - acc: 0.9334 - 56ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4629 - acc: 0.9031 - 102ms/step\n",
      "step 19/19 - loss: 0.4262 - acc: 0.8983 - 68ms/step\n",
      "Eval samples: 1200\n",
      "save checkpoint at /home/aistudio/checkpoints1/final\n"
     ]
    }
   ],
   "source": [
    "model = TextCNNModel(\r\n",
    "    vocab_size=len(vocab),\r\n",
    "    num_classes=len(train_data.label_list),\r\n",
    "    padding_idx=vocab.to_indices('[PAD]')\r\n",
    ")\r\n",
    "\r\n",
    "model = paddle.Model(model)\r\n",
    "\r\n",
    "optimizer = paddle.optimizer.Adam(\r\n",
    "    parameters=model.parameters(),\r\n",
    "    learning_rate=5e-5\r\n",
    ")\r\n",
    "\r\n",
    "loss = paddle.nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "metric = paddle.metric.Accuracy()\r\n",
    "\r\n",
    "model.prepare(\r\n",
    "    optimizer=optimizer,\r\n",
    "    loss=loss,\r\n",
    "    metrics=metric\r\n",
    ")\r\n",
    "\r\n",
    "model.fit(\r\n",
    "    train_data=train_loader,\r\n",
    "    eval_data=dev_loader,\r\n",
    "    epochs=10,\r\n",
    "    save_dir='./checkpoints1',\r\n",
    "    save_freq=5\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/10\n",
      "step  10/150 - loss: 0.6932 - acc: 0.4938 - 97ms/step\n",
      "step  20/150 - loss: 0.6919 - acc: 0.4984 - 85ms/step\n",
      "step  30/150 - loss: 0.6930 - acc: 0.4938 - 78ms/step\n",
      "step  40/150 - loss: 0.6943 - acc: 0.5012 - 79ms/step\n",
      "step  50/150 - loss: 0.6918 - acc: 0.5072 - 80ms/step\n",
      "step  60/150 - loss: 0.6919 - acc: 0.5005 - 80ms/step\n",
      "step  70/150 - loss: 0.6923 - acc: 0.5004 - 79ms/step\n",
      "step  80/150 - loss: 0.6922 - acc: 0.5004 - 79ms/step\n",
      "step  90/150 - loss: 0.6908 - acc: 0.5007 - 78ms/step\n",
      "step 100/150 - loss: 0.6926 - acc: 0.5020 - 79ms/step\n",
      "step 110/150 - loss: 0.6927 - acc: 0.5014 - 78ms/step\n",
      "step 120/150 - loss: 0.6897 - acc: 0.5022 - 78ms/step\n",
      "step 130/150 - loss: 0.6907 - acc: 0.5028 - 78ms/step\n",
      "step 140/150 - loss: 0.6891 - acc: 0.5031 - 78ms/step\n",
      "step 150/150 - loss: 0.6906 - acc: 0.5061 - 77ms/step\n",
      "save checkpoint at /home/aistudio/checkpoints2/0\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.6910 - acc: 0.7641 - 71ms/step\n",
      "step 19/19 - loss: 0.6901 - acc: 0.7608 - 54ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 2/10\n",
      "step  10/150 - loss: 0.6888 - acc: 0.7156 - 93ms/step\n",
      "step  20/150 - loss: 0.6893 - acc: 0.7211 - 84ms/step\n",
      "step  30/150 - loss: 0.6850 - acc: 0.7312 - 85ms/step\n",
      "step  40/150 - loss: 0.6821 - acc: 0.6898 - 83ms/step\n",
      "step  50/150 - loss: 0.6868 - acc: 0.6609 - 81ms/step\n",
      "step  60/150 - loss: 0.6851 - acc: 0.6482 - 79ms/step\n",
      "step  70/150 - loss: 0.6812 - acc: 0.6527 - 78ms/step\n",
      "step  80/150 - loss: 0.6838 - acc: 0.6604 - 78ms/step\n",
      "step  90/150 - loss: 0.6789 - acc: 0.6660 - 79ms/step\n",
      "step 100/150 - loss: 0.6765 - acc: 0.6767 - 79ms/step\n",
      "step 110/150 - loss: 0.6671 - acc: 0.6811 - 79ms/step\n",
      "step 120/150 - loss: 0.6680 - acc: 0.6779 - 78ms/step\n",
      "step 130/150 - loss: 0.6522 - acc: 0.6840 - 78ms/step\n",
      "step 140/150 - loss: 0.6459 - acc: 0.6941 - 78ms/step\n",
      "step 150/150 - loss: 0.6141 - acc: 0.7034 - 77ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.6276 - acc: 0.7969 - 72ms/step\n",
      "step 19/19 - loss: 0.6164 - acc: 0.7942 - 64ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 3/10\n",
      "step  10/150 - loss: 0.5631 - acc: 0.7859 - 181ms/step\n",
      "step  20/150 - loss: 0.4928 - acc: 0.8023 - 130ms/step\n",
      "step  30/150 - loss: 0.6490 - acc: 0.7958 - 112ms/step\n",
      "step  40/150 - loss: 0.5762 - acc: 0.7961 - 103ms/step\n",
      "step  50/150 - loss: 0.5554 - acc: 0.7941 - 100ms/step\n",
      "step  60/150 - loss: 0.5361 - acc: 0.7964 - 96ms/step\n",
      "step  70/150 - loss: 0.5624 - acc: 0.7973 - 94ms/step\n",
      "step  80/150 - loss: 0.4682 - acc: 0.8016 - 92ms/step\n",
      "step  90/150 - loss: 0.4253 - acc: 0.8083 - 91ms/step\n",
      "step 100/150 - loss: 0.4114 - acc: 0.8127 - 89ms/step\n",
      "step 110/150 - loss: 0.4277 - acc: 0.8168 - 89ms/step\n",
      "step 120/150 - loss: 0.4062 - acc: 0.8219 - 88ms/step\n",
      "step 130/150 - loss: 0.4528 - acc: 0.8263 - 88ms/step\n",
      "step 140/150 - loss: 0.4666 - acc: 0.8282 - 87ms/step\n",
      "step 150/150 - loss: 0.3746 - acc: 0.8319 - 85ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4961 - acc: 0.8531 - 71ms/step\n",
      "step 19/19 - loss: 0.4854 - acc: 0.8442 - 55ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 4/10\n",
      "step  10/150 - loss: 0.4354 - acc: 0.8828 - 97ms/step\n",
      "step  20/150 - loss: 0.4686 - acc: 0.8867 - 89ms/step\n",
      "step  30/150 - loss: 0.4115 - acc: 0.8891 - 82ms/step\n",
      "step  40/150 - loss: 0.4513 - acc: 0.8879 - 82ms/step\n",
      "step  50/150 - loss: 0.4400 - acc: 0.8872 - 81ms/step\n",
      "step  60/150 - loss: 0.4671 - acc: 0.8862 - 80ms/step\n",
      "step  70/150 - loss: 0.4323 - acc: 0.8866 - 80ms/step\n",
      "step  80/150 - loss: 0.4053 - acc: 0.8877 - 79ms/step\n",
      "step  90/150 - loss: 0.3862 - acc: 0.8885 - 79ms/step\n",
      "step 100/150 - loss: 0.4543 - acc: 0.8892 - 77ms/step\n",
      "step 110/150 - loss: 0.3756 - acc: 0.8913 - 77ms/step\n",
      "step 120/150 - loss: 0.4231 - acc: 0.8917 - 78ms/step\n",
      "step 130/150 - loss: 0.4760 - acc: 0.8916 - 78ms/step\n",
      "step 140/150 - loss: 0.4118 - acc: 0.8907 - 77ms/step\n",
      "step 150/150 - loss: 0.3768 - acc: 0.8925 - 76ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4741 - acc: 0.8734 - 80ms/step\n",
      "step 19/19 - loss: 0.4680 - acc: 0.8683 - 63ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 5/10\n",
      "step  10/150 - loss: 0.4106 - acc: 0.9000 - 100ms/step\n",
      "step  20/150 - loss: 0.3674 - acc: 0.9062 - 91ms/step\n",
      "step  30/150 - loss: 0.4251 - acc: 0.9073 - 86ms/step\n",
      "step  40/150 - loss: 0.4116 - acc: 0.9055 - 87ms/step\n",
      "step  50/150 - loss: 0.3991 - acc: 0.9081 - 84ms/step\n",
      "step  60/150 - loss: 0.4127 - acc: 0.9104 - 82ms/step\n",
      "step  70/150 - loss: 0.4619 - acc: 0.9109 - 81ms/step\n",
      "step  80/150 - loss: 0.4106 - acc: 0.9107 - 80ms/step\n",
      "step  90/150 - loss: 0.3970 - acc: 0.9113 - 79ms/step\n",
      "step 100/150 - loss: 0.4211 - acc: 0.9111 - 78ms/step\n",
      "step 110/150 - loss: 0.3979 - acc: 0.9119 - 78ms/step\n",
      "step 120/150 - loss: 0.3864 - acc: 0.9124 - 79ms/step\n",
      "step 130/150 - loss: 0.3891 - acc: 0.9130 - 79ms/step\n",
      "step 140/150 - loss: 0.3614 - acc: 0.9134 - 79ms/step\n",
      "step 150/150 - loss: 0.3767 - acc: 0.9137 - 79ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4461 - acc: 0.8688 - 70ms/step\n",
      "step 19/19 - loss: 0.4257 - acc: 0.8717 - 54ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 6/10\n",
      "step  10/150 - loss: 0.3510 - acc: 0.9297 - 97ms/step\n",
      "step  20/150 - loss: 0.3847 - acc: 0.9250 - 85ms/step\n",
      "step  30/150 - loss: 0.3655 - acc: 0.9255 - 83ms/step\n",
      "step  40/150 - loss: 0.3817 - acc: 0.9199 - 81ms/step\n",
      "step  50/150 - loss: 0.4170 - acc: 0.9216 - 81ms/step\n",
      "step  60/150 - loss: 0.4076 - acc: 0.9224 - 81ms/step\n",
      "step  70/150 - loss: 0.3874 - acc: 0.9230 - 81ms/step\n",
      "step  80/150 - loss: 0.4280 - acc: 0.9232 - 81ms/step\n",
      "step  90/150 - loss: 0.4151 - acc: 0.9234 - 80ms/step\n",
      "step 100/150 - loss: 0.4067 - acc: 0.9234 - 80ms/step\n",
      "step 110/150 - loss: 0.3921 - acc: 0.9224 - 80ms/step\n",
      "step 120/150 - loss: 0.3527 - acc: 0.9227 - 80ms/step\n",
      "step 130/150 - loss: 0.3779 - acc: 0.9236 - 80ms/step\n",
      "step 140/150 - loss: 0.3273 - acc: 0.9250 - 79ms/step\n",
      "step 150/150 - loss: 0.3304 - acc: 0.9270 - 78ms/step\n",
      "save checkpoint at /home/aistudio/checkpoints2/5\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4624 - acc: 0.8938 - 85ms/step\n",
      "step 19/19 - loss: 0.4668 - acc: 0.8842 - 62ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 7/10\n",
      "step  10/150 - loss: 0.4060 - acc: 0.9406 - 103ms/step\n",
      "step  20/150 - loss: 0.4450 - acc: 0.9352 - 90ms/step\n",
      "step  30/150 - loss: 0.3719 - acc: 0.9365 - 97ms/step\n",
      "step  40/150 - loss: 0.3338 - acc: 0.9355 - 97ms/step\n",
      "step  50/150 - loss: 0.3802 - acc: 0.9381 - 97ms/step\n",
      "step  60/150 - loss: 0.3523 - acc: 0.9383 - 97ms/step\n",
      "step  70/150 - loss: 0.3895 - acc: 0.9379 - 96ms/step\n",
      "step  80/150 - loss: 0.4121 - acc: 0.9375 - 94ms/step\n",
      "step  90/150 - loss: 0.4287 - acc: 0.9392 - 92ms/step\n",
      "step 100/150 - loss: 0.3917 - acc: 0.9384 - 92ms/step\n",
      "step 110/150 - loss: 0.3866 - acc: 0.9386 - 91ms/step\n",
      "step 120/150 - loss: 0.3556 - acc: 0.9385 - 89ms/step\n",
      "step 130/150 - loss: 0.4083 - acc: 0.9383 - 88ms/step\n",
      "step 140/150 - loss: 0.4081 - acc: 0.9376 - 88ms/step\n",
      "step 150/150 - loss: 0.4016 - acc: 0.9375 - 86ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4344 - acc: 0.8984 - 72ms/step\n",
      "step 19/19 - loss: 0.4240 - acc: 0.8950 - 55ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 8/10\n",
      "step  10/150 - loss: 0.3435 - acc: 0.9484 - 92ms/step\n",
      "step  20/150 - loss: 0.3530 - acc: 0.9398 - 83ms/step\n",
      "step  30/150 - loss: 0.3408 - acc: 0.9453 - 82ms/step\n",
      "step  40/150 - loss: 0.4117 - acc: 0.9480 - 83ms/step\n",
      "step  50/150 - loss: 0.3858 - acc: 0.9466 - 82ms/step\n",
      "step  60/150 - loss: 0.3283 - acc: 0.9464 - 82ms/step\n",
      "step  70/150 - loss: 0.3671 - acc: 0.9464 - 84ms/step\n",
      "step  80/150 - loss: 0.3775 - acc: 0.9445 - 83ms/step\n",
      "step  90/150 - loss: 0.3888 - acc: 0.9455 - 85ms/step\n",
      "step 100/150 - loss: 0.3805 - acc: 0.9453 - 83ms/step\n",
      "step 110/150 - loss: 0.3753 - acc: 0.9467 - 83ms/step\n",
      "step 120/150 - loss: 0.3846 - acc: 0.9473 - 82ms/step\n",
      "step 130/150 - loss: 0.3644 - acc: 0.9478 - 81ms/step\n",
      "step 140/150 - loss: 0.3611 - acc: 0.9472 - 80ms/step\n",
      "step 150/150 - loss: 0.3982 - acc: 0.9469 - 79ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4403 - acc: 0.9031 - 76ms/step\n",
      "step 19/19 - loss: 0.4703 - acc: 0.8917 - 58ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 9/10\n",
      "step  10/150 - loss: 0.3378 - acc: 0.9625 - 99ms/step\n",
      "step  20/150 - loss: 0.3322 - acc: 0.9594 - 88ms/step\n",
      "step  30/150 - loss: 0.3685 - acc: 0.9547 - 85ms/step\n",
      "step  40/150 - loss: 0.4132 - acc: 0.9527 - 84ms/step\n",
      "step  50/150 - loss: 0.3717 - acc: 0.9531 - 86ms/step\n",
      "step  60/150 - loss: 0.3620 - acc: 0.9539 - 85ms/step\n",
      "step  70/150 - loss: 0.3423 - acc: 0.9538 - 85ms/step\n",
      "step  80/150 - loss: 0.3912 - acc: 0.9529 - 85ms/step\n",
      "step  90/150 - loss: 0.3591 - acc: 0.9533 - 85ms/step\n",
      "step 100/150 - loss: 0.3619 - acc: 0.9530 - 84ms/step\n",
      "step 110/150 - loss: 0.4303 - acc: 0.9514 - 83ms/step\n",
      "step 120/150 - loss: 0.4040 - acc: 0.9509 - 84ms/step\n",
      "step 130/150 - loss: 0.3385 - acc: 0.9506 - 84ms/step\n",
      "step 140/150 - loss: 0.3660 - acc: 0.9501 - 83ms/step\n",
      "step 150/150 - loss: 0.3731 - acc: 0.9495 - 82ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4433 - acc: 0.9125 - 73ms/step\n",
      "step 19/19 - loss: 0.4249 - acc: 0.9050 - 56ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 10/10\n",
      "step  10/150 - loss: 0.3505 - acc: 0.9484 - 87ms/step\n",
      "step  20/150 - loss: 0.3611 - acc: 0.9555 - 82ms/step\n",
      "step  30/150 - loss: 0.3580 - acc: 0.9563 - 80ms/step\n",
      "step  40/150 - loss: 0.3652 - acc: 0.9566 - 81ms/step\n",
      "step  50/150 - loss: 0.3565 - acc: 0.9550 - 81ms/step\n",
      "step  60/150 - loss: 0.3550 - acc: 0.9565 - 79ms/step\n",
      "step  70/150 - loss: 0.3675 - acc: 0.9563 - 80ms/step\n",
      "step  80/150 - loss: 0.3564 - acc: 0.9564 - 80ms/step\n",
      "step  90/150 - loss: 0.3912 - acc: 0.9550 - 81ms/step\n",
      "step 100/150 - loss: 0.3378 - acc: 0.9563 - 82ms/step\n",
      "step 110/150 - loss: 0.3510 - acc: 0.9560 - 81ms/step\n",
      "step 120/150 - loss: 0.3939 - acc: 0.9561 - 80ms/step\n",
      "step 130/150 - loss: 0.3279 - acc: 0.9563 - 80ms/step\n",
      "step 140/150 - loss: 0.3174 - acc: 0.9565 - 81ms/step\n",
      "step 150/150 - loss: 0.3569 - acc: 0.9565 - 80ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4405 - acc: 0.9047 - 79ms/step\n",
      "step 19/19 - loss: 0.4301 - acc: 0.8992 - 71ms/step\n",
      "Eval samples: 1200\n",
      "save checkpoint at /home/aistudio/checkpoints2/final\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMAttentionModel(\r\n",
    "    vocab_size=len(vocab),\r\n",
    "    num_classes=len(train_data.label_list),\r\n",
    "    padding_idx=vocab.to_indices('[PAD]'),\r\n",
    "    attention_layer=SelfAttention()\r\n",
    ")\r\n",
    "\r\n",
    "model = paddle.Model(model)\r\n",
    "\r\n",
    "optimizer = paddle.optimizer.Adam(\r\n",
    "    parameters=model.parameters(),\r\n",
    "    learning_rate=5e-5\r\n",
    ")\r\n",
    "\r\n",
    "loss = paddle.nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "metric = paddle.metric.Accuracy()\r\n",
    "\r\n",
    "model.prepare(\r\n",
    "    optimizer=optimizer,\r\n",
    "    loss=loss,\r\n",
    "    metrics=metric\r\n",
    ")\r\n",
    "\r\n",
    "model.fit(\r\n",
    "    train_data=train_loader,\r\n",
    "    eval_data=dev_loader,\r\n",
    "    epochs=10,\r\n",
    "    save_dir='./checkpoints2',\r\n",
    "    save_freq=5\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss value printed in the log is the current step, and the metric is the average value of previous steps.\n",
      "Epoch 1/10\n",
      "step  10/150 - loss: 0.6931 - acc: 0.4828 - 99ms/step\n",
      "step  20/150 - loss: 0.6928 - acc: 0.4906 - 102ms/step\n",
      "step  30/150 - loss: 0.6925 - acc: 0.4964 - 107ms/step\n",
      "step  40/150 - loss: 0.6925 - acc: 0.4953 - 102ms/step\n",
      "step  50/150 - loss: 0.6931 - acc: 0.4978 - 98ms/step\n",
      "step  60/150 - loss: 0.6952 - acc: 0.5003 - 95ms/step\n",
      "step  70/150 - loss: 0.6938 - acc: 0.5029 - 93ms/step\n",
      "step  80/150 - loss: 0.6929 - acc: 0.4990 - 92ms/step\n",
      "step  90/150 - loss: 0.6924 - acc: 0.5014 - 91ms/step\n",
      "step 100/150 - loss: 0.6928 - acc: 0.5106 - 92ms/step\n",
      "step 110/150 - loss: 0.6927 - acc: 0.5119 - 91ms/step\n",
      "step 120/150 - loss: 0.6891 - acc: 0.5115 - 91ms/step\n",
      "step 130/150 - loss: 0.6918 - acc: 0.5113 - 91ms/step\n",
      "step 140/150 - loss: 0.6904 - acc: 0.5100 - 90ms/step\n",
      "step 150/150 - loss: 0.6898 - acc: 0.5216 - 90ms/step\n",
      "save checkpoint at /home/aistudio/checkpoints3/0\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.6909 - acc: 0.5641 - 75ms/step\n",
      "step 19/19 - loss: 0.6901 - acc: 0.5492 - 58ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 2/10\n",
      "step  10/150 - loss: 0.6920 - acc: 0.4828 - 99ms/step\n",
      "step  20/150 - loss: 0.6888 - acc: 0.5547 - 91ms/step\n",
      "step  30/150 - loss: 0.6923 - acc: 0.5844 - 88ms/step\n",
      "step  40/150 - loss: 0.6876 - acc: 0.6180 - 84ms/step\n",
      "step  50/150 - loss: 0.6870 - acc: 0.6587 - 83ms/step\n",
      "step  60/150 - loss: 0.6855 - acc: 0.6672 - 83ms/step\n",
      "step  70/150 - loss: 0.6808 - acc: 0.6533 - 82ms/step\n",
      "step  80/150 - loss: 0.6824 - acc: 0.6621 - 81ms/step\n",
      "step  90/150 - loss: 0.6828 - acc: 0.6655 - 81ms/step\n",
      "step 100/150 - loss: 0.6749 - acc: 0.6766 - 81ms/step\n",
      "step 110/150 - loss: 0.6713 - acc: 0.6928 - 81ms/step\n",
      "step 120/150 - loss: 0.6632 - acc: 0.6993 - 81ms/step\n",
      "step 130/150 - loss: 0.6521 - acc: 0.7020 - 82ms/step\n",
      "step 140/150 - loss: 0.6388 - acc: 0.7067 - 82ms/step\n",
      "step 150/150 - loss: 0.6189 - acc: 0.7123 - 81ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.6269 - acc: 0.8109 - 88ms/step\n",
      "step 19/19 - loss: 0.6116 - acc: 0.8033 - 64ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 3/10\n",
      "step  10/150 - loss: 0.5563 - acc: 0.8391 - 98ms/step\n",
      "step  20/150 - loss: 0.4998 - acc: 0.8352 - 96ms/step\n",
      "step  30/150 - loss: 0.4990 - acc: 0.8359 - 93ms/step\n",
      "step  40/150 - loss: 0.4696 - acc: 0.8422 - 91ms/step\n",
      "step  50/150 - loss: 0.5557 - acc: 0.8325 - 89ms/step\n",
      "step  60/150 - loss: 0.5181 - acc: 0.8378 - 87ms/step\n",
      "step  70/150 - loss: 0.4858 - acc: 0.8373 - 86ms/step\n",
      "step  80/150 - loss: 0.5207 - acc: 0.8365 - 85ms/step\n",
      "step  90/150 - loss: 0.4801 - acc: 0.8358 - 85ms/step\n",
      "step 100/150 - loss: 0.4763 - acc: 0.8377 - 84ms/step\n",
      "step 110/150 - loss: 0.4691 - acc: 0.8384 - 85ms/step\n",
      "step 120/150 - loss: 0.4303 - acc: 0.8405 - 85ms/step\n",
      "step 130/150 - loss: 0.4473 - acc: 0.8407 - 84ms/step\n",
      "step 140/150 - loss: 0.4346 - acc: 0.8430 - 84ms/step\n",
      "step 150/150 - loss: 0.4790 - acc: 0.8441 - 82ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4958 - acc: 0.8469 - 72ms/step\n",
      "step 19/19 - loss: 0.4412 - acc: 0.8450 - 55ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 4/10\n",
      "step  10/150 - loss: 0.3815 - acc: 0.8703 - 97ms/step\n",
      "step  20/150 - loss: 0.4569 - acc: 0.8758 - 89ms/step\n",
      "step  30/150 - loss: 0.4592 - acc: 0.8760 - 86ms/step\n",
      "step  40/150 - loss: 0.5880 - acc: 0.8539 - 83ms/step\n",
      "step  50/150 - loss: 0.4303 - acc: 0.8441 - 83ms/step\n",
      "step  60/150 - loss: 0.4575 - acc: 0.8414 - 86ms/step\n",
      "step  70/150 - loss: 0.4340 - acc: 0.8440 - 85ms/step\n",
      "step  80/150 - loss: 0.3875 - acc: 0.8477 - 86ms/step\n",
      "step  90/150 - loss: 0.4559 - acc: 0.8490 - 86ms/step\n",
      "step 100/150 - loss: 0.3698 - acc: 0.8525 - 86ms/step\n",
      "step 110/150 - loss: 0.4203 - acc: 0.8540 - 85ms/step\n",
      "step 120/150 - loss: 0.4167 - acc: 0.8560 - 85ms/step\n",
      "step 130/150 - loss: 0.3502 - acc: 0.8578 - 85ms/step\n",
      "step 140/150 - loss: 0.3992 - acc: 0.8588 - 85ms/step\n",
      "step 150/150 - loss: 0.4213 - acc: 0.8589 - 83ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4694 - acc: 0.8469 - 70ms/step\n",
      "step 19/19 - loss: 0.5008 - acc: 0.8425 - 54ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 5/10\n",
      "step  10/150 - loss: 0.4469 - acc: 0.8797 - 94ms/step\n",
      "step  20/150 - loss: 0.3682 - acc: 0.8906 - 99ms/step\n",
      "step  30/150 - loss: 0.5091 - acc: 0.8823 - 103ms/step\n",
      "step  40/150 - loss: 0.4487 - acc: 0.8871 - 96ms/step\n",
      "step  50/150 - loss: 0.4417 - acc: 0.8828 - 93ms/step\n",
      "step  60/150 - loss: 0.4089 - acc: 0.8862 - 92ms/step\n",
      "step  70/150 - loss: 0.4578 - acc: 0.8844 - 91ms/step\n",
      "step  80/150 - loss: 0.4019 - acc: 0.8852 - 89ms/step\n",
      "step  90/150 - loss: 0.4483 - acc: 0.8849 - 90ms/step\n",
      "step 100/150 - loss: 0.4622 - acc: 0.8842 - 88ms/step\n",
      "step 110/150 - loss: 0.5243 - acc: 0.8832 - 88ms/step\n",
      "step 120/150 - loss: 0.4976 - acc: 0.8839 - 87ms/step\n",
      "step 130/150 - loss: 0.4552 - acc: 0.8843 - 86ms/step\n",
      "step 140/150 - loss: 0.4410 - acc: 0.8843 - 86ms/step\n",
      "step 150/150 - loss: 0.4560 - acc: 0.8857 - 85ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4650 - acc: 0.8750 - 72ms/step\n",
      "step 19/19 - loss: 0.4488 - acc: 0.8700 - 55ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 6/10\n",
      "step  10/150 - loss: 0.4438 - acc: 0.9016 - 106ms/step\n",
      "step  20/150 - loss: 0.4344 - acc: 0.9016 - 96ms/step\n",
      "step  30/150 - loss: 0.3866 - acc: 0.9000 - 93ms/step\n",
      "step  40/150 - loss: 0.3834 - acc: 0.8961 - 89ms/step\n",
      "step  50/150 - loss: 0.3764 - acc: 0.8978 - 86ms/step\n",
      "step  60/150 - loss: 0.4058 - acc: 0.8958 - 85ms/step\n",
      "step  70/150 - loss: 0.4492 - acc: 0.8951 - 84ms/step\n",
      "step  80/150 - loss: 0.4420 - acc: 0.8961 - 84ms/step\n",
      "step  90/150 - loss: 0.3949 - acc: 0.8984 - 83ms/step\n",
      "step 100/150 - loss: 0.4151 - acc: 0.8994 - 83ms/step\n",
      "step 110/150 - loss: 0.4050 - acc: 0.8999 - 81ms/step\n",
      "step 120/150 - loss: 0.3930 - acc: 0.8996 - 81ms/step\n",
      "step 130/150 - loss: 0.3740 - acc: 0.8993 - 81ms/step\n",
      "step 140/150 - loss: 0.4271 - acc: 0.9009 - 81ms/step\n",
      "step 150/150 - loss: 0.4083 - acc: 0.9008 - 80ms/step\n",
      "save checkpoint at /home/aistudio/checkpoints3/5\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4838 - acc: 0.8797 - 77ms/step\n",
      "step 19/19 - loss: 0.4492 - acc: 0.8717 - 61ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 7/10\n",
      "step  10/150 - loss: 0.3906 - acc: 0.8891 - 105ms/step\n",
      "step  20/150 - loss: 0.3834 - acc: 0.8961 - 95ms/step\n",
      "step  30/150 - loss: 0.4031 - acc: 0.9010 - 92ms/step\n",
      "step  40/150 - loss: 0.4641 - acc: 0.9039 - 90ms/step\n",
      "step  50/150 - loss: 0.4269 - acc: 0.9050 - 87ms/step\n",
      "step  60/150 - loss: 0.4844 - acc: 0.8995 - 84ms/step\n",
      "step  70/150 - loss: 0.4003 - acc: 0.9007 - 83ms/step\n",
      "step  80/150 - loss: 0.4070 - acc: 0.9014 - 84ms/step\n",
      "step  90/150 - loss: 0.3738 - acc: 0.9031 - 84ms/step\n",
      "step 100/150 - loss: 0.3887 - acc: 0.9066 - 83ms/step\n",
      "step 110/150 - loss: 0.3949 - acc: 0.9072 - 82ms/step\n",
      "step 120/150 - loss: 0.3964 - acc: 0.9074 - 82ms/step\n",
      "step 130/150 - loss: 0.4190 - acc: 0.9075 - 81ms/step\n",
      "step 140/150 - loss: 0.3674 - acc: 0.9090 - 81ms/step\n",
      "step 150/150 - loss: 0.3909 - acc: 0.9099 - 80ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4659 - acc: 0.8766 - 72ms/step\n",
      "step 19/19 - loss: 0.4321 - acc: 0.8742 - 56ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 8/10\n",
      "step  10/150 - loss: 0.4173 - acc: 0.9203 - 104ms/step\n",
      "step  20/150 - loss: 0.4149 - acc: 0.9164 - 95ms/step\n",
      "step  30/150 - loss: 0.4459 - acc: 0.9193 - 92ms/step\n",
      "step  40/150 - loss: 0.3967 - acc: 0.9180 - 90ms/step\n",
      "step  50/150 - loss: 0.3762 - acc: 0.9213 - 87ms/step\n",
      "step  60/150 - loss: 0.3562 - acc: 0.9242 - 87ms/step\n",
      "step  70/150 - loss: 0.4244 - acc: 0.9250 - 85ms/step\n",
      "step  80/150 - loss: 0.3773 - acc: 0.9248 - 85ms/step\n",
      "step  90/150 - loss: 0.3917 - acc: 0.9247 - 83ms/step\n",
      "step 100/150 - loss: 0.3834 - acc: 0.9233 - 82ms/step\n",
      "step 110/150 - loss: 0.4171 - acc: 0.9230 - 82ms/step\n",
      "step 120/150 - loss: 0.3825 - acc: 0.9225 - 82ms/step\n",
      "step 130/150 - loss: 0.4374 - acc: 0.9228 - 81ms/step\n",
      "step 140/150 - loss: 0.3642 - acc: 0.9238 - 82ms/step\n",
      "step 150/150 - loss: 0.4183 - acc: 0.9244 - 80ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4615 - acc: 0.8922 - 73ms/step\n",
      "step 19/19 - loss: 0.4543 - acc: 0.8825 - 56ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 9/10\n",
      "step  10/150 - loss: 0.4098 - acc: 0.9391 - 101ms/step\n",
      "step  20/150 - loss: 0.3716 - acc: 0.9352 - 97ms/step\n",
      "step  30/150 - loss: 0.4163 - acc: 0.9328 - 115ms/step\n",
      "step  40/150 - loss: 0.4166 - acc: 0.9324 - 113ms/step\n",
      "step  50/150 - loss: 0.3882 - acc: 0.9297 - 109ms/step\n",
      "step  60/150 - loss: 0.4274 - acc: 0.9299 - 106ms/step\n",
      "step  70/150 - loss: 0.4119 - acc: 0.9286 - 102ms/step\n",
      "step  80/150 - loss: 0.4031 - acc: 0.9271 - 99ms/step\n",
      "step  90/150 - loss: 0.3854 - acc: 0.9269 - 96ms/step\n",
      "step 100/150 - loss: 0.3796 - acc: 0.9277 - 94ms/step\n",
      "step 110/150 - loss: 0.4016 - acc: 0.9283 - 94ms/step\n",
      "step 120/150 - loss: 0.3838 - acc: 0.9276 - 93ms/step\n",
      "step 130/150 - loss: 0.3754 - acc: 0.9264 - 91ms/step\n",
      "step 140/150 - loss: 0.3911 - acc: 0.9273 - 90ms/step\n",
      "step 150/150 - loss: 0.3749 - acc: 0.9280 - 89ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4473 - acc: 0.8922 - 70ms/step\n",
      "step 19/19 - loss: 0.4231 - acc: 0.8867 - 54ms/step\n",
      "Eval samples: 1200\n",
      "Epoch 10/10\n",
      "step  10/150 - loss: 0.3934 - acc: 0.9219 - 98ms/step\n",
      "step  20/150 - loss: 0.3892 - acc: 0.9211 - 86ms/step\n",
      "step  30/150 - loss: 0.3954 - acc: 0.9234 - 85ms/step\n",
      "step  40/150 - loss: 0.4606 - acc: 0.9223 - 85ms/step\n",
      "step  50/150 - loss: 0.4378 - acc: 0.9153 - 83ms/step\n",
      "step  60/150 - loss: 0.4494 - acc: 0.9062 - 82ms/step\n",
      "step  70/150 - loss: 0.4036 - acc: 0.9080 - 82ms/step\n",
      "step  80/150 - loss: 0.4293 - acc: 0.9107 - 82ms/step\n",
      "step  90/150 - loss: 0.3905 - acc: 0.9130 - 81ms/step\n",
      "step 100/150 - loss: 0.3982 - acc: 0.9141 - 81ms/step\n",
      "step 110/150 - loss: 0.4020 - acc: 0.9145 - 82ms/step\n",
      "step 120/150 - loss: 0.4263 - acc: 0.9154 - 84ms/step\n",
      "step 130/150 - loss: 0.3641 - acc: 0.9167 - 83ms/step\n",
      "step 140/150 - loss: 0.3844 - acc: 0.9184 - 84ms/step\n",
      "step 150/150 - loss: 0.4137 - acc: 0.9198 - 83ms/step\n",
      "Eval begin...\n",
      "step 10/19 - loss: 0.4357 - acc: 0.8984 - 72ms/step\n",
      "step 19/19 - loss: 0.4483 - acc: 0.8867 - 55ms/step\n",
      "Eval samples: 1200\n",
      "save checkpoint at /home/aistudio/checkpoints3/final\n"
     ]
    }
   ],
   "source": [
    "model = BiLSTMAttentionModel(\r\n",
    "    vocab_size=len(vocab),\r\n",
    "    num_classes=len(train_data.label_list),\r\n",
    "    padding_idx=vocab.to_indices('[PAD]'),\r\n",
    "    attention_layer=SelfInteractiveAttention()\r\n",
    ")\r\n",
    "\r\n",
    "model = paddle.Model(model)\r\n",
    "\r\n",
    "optimizer = paddle.optimizer.Adam(\r\n",
    "    parameters=model.parameters(),\r\n",
    "    learning_rate=5e-5\r\n",
    ")\r\n",
    "\r\n",
    "loss = paddle.nn.CrossEntropyLoss()\r\n",
    "\r\n",
    "metric = paddle.metric.Accuracy()\r\n",
    "\r\n",
    "model.prepare(\r\n",
    "    optimizer=optimizer,\r\n",
    "    loss=loss,\r\n",
    "    metrics=metric\r\n",
    ")\r\n",
    "\r\n",
    "model.fit(\r\n",
    "    train_data=train_loader,\r\n",
    "    eval_data=dev_loader,\r\n",
    "    epochs=10,\r\n",
    "    save_dir='./checkpoints3',\r\n",
    "    save_freq=5\r\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 7. 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans_fn = partial(convert_example, tokenizer=tokenizer, is_test=True)\r\n",
    "\r\n",
    "batchify_fn = lambda samples, fn=Tuple(\r\n",
    "    Pad(axis=0, pad_val=vocab['[PAD]']),  # input_ids\r\n",
    "    Stack(dtype=\"int64\"),  # seq len\r\n",
    "): [data for data in fn(samples)]\r\n",
    "\r\n",
    "test_loader = create_dataloader(\r\n",
    "    test_data,\r\n",
    "    trans_fn=trans_fn,\r\n",
    "    batch_size=batch_size,\r\n",
    "    mode='test',\r\n",
    "    batchify_fn=batchify_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict begin...\n",
      "step 19/19 [==============================] - ETA: 2s - 151ms/st - ETA: 1s - 100ms/st - ETA: 1s - 88ms/step - ETA: 0s - 80ms/ste - ETA: 0s - 75ms/ste - ETA: 0s - 72ms/ste - ETA: 0s - 69ms/ste - ETA: 0s - 67ms/ste - ETA: 0s - 62ms/ste - 60ms/step          \n",
      "Predict samples: 1200\n",
      "Data: 这个宾馆比较陈旧了，特价的房间也很一般。总体来说一般 \t Label: negative\n",
      "Data: 怀着十分激动的心情放映，可是看着看着发现，在放映完毕后，出现一集米老鼠的动画片！开始还怀疑是不是赠送的个别现象，可是后来发现每张DVD后面都有！真不知道生产商怎么想的，我想看的是猫和老鼠，不是米老鼠！如果厂家是想赠送的话，那就全套米老鼠和唐老鸭都赠送，只在每张DVD后面添加一集算什么？？简直是画蛇添足！！ \t Label: negative\n",
      "Data: 还稍微重了点，可能是硬盘大的原故，还要再轻半斤就好了。其他要进一步验证。贴的几种膜气泡较多，用不了多久就要更换了，屏幕膜稍好点，但比没有要强多了。建议配赠几张膜让用用户自己贴。 \t Label: negative\n",
      "Data: 交通方便；环境很好；服务态度很好 房间较小 \t Label: positive\n",
      "Data: 不错，作者的观点很颠覆目前中国父母的教育方式，其实古人们对于教育已经有了很系统的体系了，可是现在的父母以及祖父母们更多的娇惯纵容孩子，放眼看去自私的孩子是大多数，父母觉得自己的孩子在外面只要不吃亏就是好事，完全把古人几千年总结的教育古训抛在的九霄云外。所以推荐准妈妈们可以在等待宝宝降临的时候，好好学习一下，怎么把孩子教育成一个有爱心、有责任心、宽容、大度的人。 \t Label: positive\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "label_map = {0: 'negative', 1: 'positive'}\r\n",
    "\r\n",
    "# 采用最优模型进行预测\r\n",
    "model = BiLSTMAttentionModel(\r\n",
    "    vocab_size=len(vocab),\r\n",
    "    num_classes=len(train_data.label_list),\r\n",
    "    padding_idx=vocab.to_indices('[PAD]'),\r\n",
    "    attention_layer=SelfAttention()\r\n",
    ")\r\n",
    "state_dict = paddle.load('./checkpoints2/final.pdparams')\r\n",
    "model.set_dict(state_dict)\r\n",
    "model = paddle.Model(model)\r\n",
    "model.prepare(\r\n",
    "    optimizer=optimizer,\r\n",
    "    loss=loss,\r\n",
    "    metrics=metric\r\n",
    ")\r\n",
    "# 将读入的数据batch化处理，便于模型batch化运算。\r\n",
    "# batch中的每个句子将会padding到这个batch中的文本最大长度batch_max_seq_len。\r\n",
    "# 当文本长度大于batch_max_seq时，将会截断到batch_max_seq_len；当文本长度小于batch_max_seq时，将会padding补齐到batch_max_seq_len.\r\n",
    "\r\n",
    "results = model.predict(test_loader, batch_size=64)[0]\r\n",
    "predictions = []\r\n",
    "for batch_probs in results:\r\n",
    "    # 映射分类label\r\n",
    "    idx = np.argmax(batch_probs, axis=-1)\r\n",
    "    idx = idx.tolist()\r\n",
    "    labels = [label_map[i] for i in idx]\r\n",
    "    predictions.extend(labels)\r\n",
    "\r\n",
    "# 看看预测数据前5个样例分类结果\r\n",
    "for idx, data in enumerate(test_data.data[:5]):\r\n",
    "    print('Data: {} \\t Label: {}'.format(data['text'], predictions[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
